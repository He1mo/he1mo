---
layout: page
title: 我的机器替我决策，我要为决策负责吗？
categories:
     - 学习笔记
---

#### 机器智能决策时代，应该由人负责吗？
>现如今，计算机通过分析大数据与智能算法代替人类做出更多的决策，然而unreasonable（不可理喻，不讲道理）计算机算法缺并不能在社会科学中能够做到飞行数据或者桥梁数据的分析计算，因为在混乱的人类事务中并无客观标准可供计算。

*  “机器学习”的进步
现代的机器学习与传统的编程不同，计算机通过对给予大数据，包括Unstructured Data非结构化数据的学习，给出一个根据概率性的答案：“这个可能像是你在寻找的东西”，得到一种相关关系。

*  以机器招聘算法系统为例
>给予机器以前的员工数据进行培训， 并指示寻找和雇用像公司现有的高绩效者这样的人。这样一来显得招聘似乎变得更加客观了。招聘系统也可以通过分析每个应聘人员的数字面包屑来推断聘用该员工是否具有诸如抑郁症等风险，从而做出决策。但事实上，当机器在学习以往已具有招聘偏见的数据中时，反馈我们的偏见， 这些系统会继承我们的偏见，并把它们放大，我们骗自己说：“我们只做客观，中立的预测。将这种责任推到了机器身上。

*  威斯康星的算法偏见
即使并未公开算法，ProPublica还是通过已公开的数据推算出算法是具有偏见，且预测能力很差，错误的把黑人被告未来犯罪的可能性 标记为白人的两倍。算法无法为最终后果承担悲剧性责任。

*  过滤推流的Facebook与未过滤新闻推流的Twitter
Facebook会为人推送朋友点赞的ALS冰桶挑战慈善信息，却用参与度推荐点赞分析过滤掉了人们不会点赞的白人警察枪杀黑人的游行新闻。机器将如此艰涩重要的新闻信息过滤，那也许以后机器会继续做出类似的决定。

*  而我们并不知道它其中的运算，而这时候就会没人负责这个责任，会推脱说这是机器的责任，与我们无关。

* 当机器智能出现诸如此类的不符合人类事务常理的的时候人们总是始料不及的，并且为之感到沮丧。

#### Math-washing不是人们的免责卡
我认为我们不该逃避责任，不应该把应该承担的责任推到机器身上吧？人工智能不是我们的免责（道德规范）卡。相反我们更需要培养对算法怀疑，审查与调查。应该让计算机来帮助我们在混乱的人类事务中做出更好的决定，且人们更应该承担起对决定判断的责任，坚持人类道德。